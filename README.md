# Projet : Mise en ≈ìuvre d'un Data Lakehouse dirig√© par Eric Kloeckle

[cite_start]Ce projet consiste √† impl√©menter un pipeline complet de traitement et d'ingestion de donn√©es pour construire un Data Lakehouse[cite: 1, 4]. [cite_start]Le processus couvre l'ensemble de la cha√Æne de traitement, de la collecte de donn√©es brutes (fichiers HTML) jusqu'√† leur visualisation dans des outils de BI[cite: 5].

Le flux de traitement des donn√©es suit les √©tapes suivantes :
[cite_start]**Collecte ‚Üí Ingestion ‚Üí Extraction ‚Üí Transformation ‚Üí Analyse / Reporting**[cite: 9].

## üìÇ Sources des donn√©es

[cite_start]Les donn√©es √† la source de ce projet sont des fichiers HTML provenant des sites **LinkedIn** et **Glassdoor**[cite: 2, 11]. [cite_start]Ces fichiers, fournis dans le dossier `0_SOURCE_WEB` [cite: 22][cite_start], contiennent trois types d'informations[cite: 10]:

* [cite_start]Offres d'emploi (INFO-EMP) [cite: 10]
* [cite_start]Informations sur les entreprises (INFO-SOC) [cite: 10]
* [cite_start]Avis d'employ√©s sur ces entreprises (AVIS-SOC) [cite: 10]

## üèõÔ∏è Architecture du Data Lakehouse

[cite_start]L'architecture du Data Lakehouse est divis√©e en plusieurs zones, chacune ayant un r√¥le d√©fini[cite: 68, 69]:

| Zone | R√¥le | Contenu |
| :--- | :--- | :--- |
| **`00_METADATA`** | M√©ta-donn√©es pour chaque √©tape du projet, les donn√©es "curated_zone" ont √©t√© plac√©s ici pour respecter la logique des donn√©es descriptives du projet.
| **`0_SOURCE_WEB`** | Donn√©es sources brutes | Fichiers HTML source (LinkedIn et Glassdoor) |
| **`1_LANDING_ZONE`** | Zone d'ingestion (donn√©es brutes) | Fichiers HTML copi√©s + Fichier CSV M√©tadonn√©es Techniques |
| **`3_PRODUCTION_ZONE`** | Zone analytique (REFINED) | Donn√©es structur√©es en mod√®le d√©cisionnel pour la BI |

---

## ‚öôÔ∏è Phases du projet

[cite_start]L'impl√©mentation est d√©compos√©e en quatre phases principales[cite: 18]:

### [cite_start]Phase 0 : Recherche des sources de donn√©es [cite: 19]
[cite_start]Cette phase est d√©j√† compl√©t√©e[cite: 21]. [cite_start]Les donn√©es sources sont fournies dans le dossier `0_SOURCE_WEB`[cite: 22, 23]. [cite_start]Aucun travail n'est √† r√©aliser pour cette √©tape[cite: 21].

### [cite_start]Phase 1 : Ingestion (vers `1_LANDING_ZONE`) [cite: 24]
* [cite_start]**Action :** Copier les fichiers HTML depuis `0_SOURCE_WEB` vers `1_LANDING_ZONE`[cite: 26].
* [cite_start]**Action :** Enregistrer simultan√©ment les ¬´ m√©tadonn√©es techniques ¬ª (date, chemins, type, etc.) dans un fichier CSV[cite: 27].
* [cite_start]**Livrables :** Scripts Python [cite: 40][cite_start], fichiers sources copi√©s en LANDING ZONE [cite: 41][cite_start], fichier de m√©tadonn√©es techniques[cite: 42].

### [cite_start]Phase 2 : Extraction (vers `2_CURATED_ZONE`) [cite: 45]
* [cite_start]**Action :** Lire le fichier de m√©tadonn√©es techniques pour localiser et traiter chaque fichier HTML pr√©sent en LANDING ZONE[cite: 46].
* [cite_start]**Action :** Extraire les ¬´ donn√©es descriptives ¬ª (nom soci√©t√©, ville, intitul√© emploi, avis, note, etc.) contenues dans les fichiers HTML[cite: 47].
* [cite_start]**Action :** Stocker ces donn√©es extraites dans un fichier CSV de ¬´ m√©tadonn√©es descriptives ¬ª[cite: 47, 51].
* [cite_start]**Livrables :** Script Python [cite: 50][cite_start], fichier de m√©tadonn√©es descriptives[cite: 51].

### [cite_start]Phase 3 : ETL et Data Warehouse (vers `3_PRODUCTION_ZONE`) [cite: 53, 54]
* [cite_start]**Action :** √Ä partir du fichier de m√©tadonn√©es descriptives, utiliser un ETL (ou script Python) pour transformer, enrichir et charger les donn√©es vers la zone `3_PRODUCTION_ZONE` (REFINED ZONE)[cite: 55].
* [cite_start]**Action :** Mod√©liser et impl√©menter une structure de donn√©es d√©cisionnelle (√©toile, flocon) qui constituera le Data Warehouse[cite: 56].
* [cite_start]**Livrables :** Scripts ETL [cite: 58][cite_start], mod√®le de donn√©es d√©cisionnel impl√©ment√©[cite: 59].

### [cite_start]Phase 4 : Reporting et Analyse [cite: 60]
* [cite_start]**Action :** Concevoir des tableaux de bord BI[cite: 62].
* [cite_start]**Action :** Utiliser des outils d'analyse pour explorer et afficher les donn√©es[cite: 63].
* [cite_start]**Livrables :** Rapports d'analyses et tableaux de bord BI dynamiques[cite: 66].

---

## [cite_start]üí° Bonnes pratiques [cite: 70]

* [cite_start]**Collecte non destructive :** Modification des objets sources interdite[cite: 71].
* [cite_start]**Tra√ßabilit√© :** Assur√©e via les m√©tadonn√©es techniques[cite: 71].
* [cite_start]**√âvolutivit√© :** Utilisation d'une structure "verticale" pour les fichiers de m√©tadonn√©es[cite: 72].
